Introduction
Patients with breast cancer (BC) are at increased risk for cognitive changes prior to, during, and after treatment ends. Estimates vary, but 15–75% or more of breast cancer survivors may exhibit objective cancer-related cognitive impairments (CRCI) with impairments most commonly reported in the domains of memory, executive functioning, and attention (Bray et al. 2018; Janelsins et al. 2014). Prevalence rates for CRCI are even higher when self-report measures of cognitive functioning are used, with estimated prevalence in over three quarters of patients (i.e., 78% or more) (Bray et al. 2018). CRCI has been observed in BC survivors up to 20 years after treatment (Amidi et al. 2015; Koppelmans et al. 2012) and is associated with reduced quality of life and survival (Boykoff et al. 2009; Robb et al. 2010) making it a significant adverse event.
Being able to predict who will likely experience CRCI could significantly enhance patient care and potentially reduce economic and human costs associated with this adverse event. Accurately predicting which individuals will develop this sequelae from traditional measures including clinical variables, self-reports, and behavioral assessments, including neuropsychological testing, is a challenge for researchers (Gabrieli et al. 2015). These measures may lack sensitivity to capture individual variation compared to high dimensional information such as genomic and neuroimaging data. In fact, genomic and neuroimaging data have outperformed or significantly enhanced low dimensional data models in predicting future outcomes (Gabrieli et al. 2015).
Objective measures of CRCI are typically obtained using standardized cognitive tests. These have historically been considered the “gold standard” for characterizing CRCI. There is often a discrepancy between objective and subjective assessments of CRCI (Bray et al. 2018; Hutchinson et al. 2012) and subjective outcomes tend to be more highly influenced by psychological distress. These characteristics of subjective cognitive effects may result in dismissal of patient complaints. However, patient reported outcomes of cognitive function are often a more accurate reflection of everyday functioning across time compared to neuropsychological tests (Nelson and Suls 2013) and therefore may have improved ecological validity (Becker et al. 2015; Boykoff et al. 2009; Player et al. 2014; Von Ah et al. 2013).
Subjective cognitive function falls under the umbrella of patient reported outcomes (PROs). PROs are becoming increasingly appreciated as a means to comprehensively understanding cancer care and the impact cancer has on patients’ daily lives (Smith et al. 2016). PROs can detect symptoms earlier and more reliably than other measures in cancer clinical trials (Gotay et al. 2008). Routine monitoring of symptoms using PRO measures (PROMs) over time as part of routine cancer care has also been shown to improve overall survival, reduce ER admissions (Basch et al. 2016) and patient symptoms (Strasser et al. 2016) compared to usual care.
Neuroimaging studies indicate that the final common biological pathway for CRCI etiology is altered brain structure and function (Deprez et al. 2018). Several studies including our own have demonstrated correlation between patient reported outcomes of cognitive impairments (PRO-Cog) and neuroimaging metrics (Kesler et al. 2011, 2013a, b; McDonald et al. 2013). Our group recently demonstrated that functional connectome (brain network) properties derived from baseline resting state fMRI (rsfMRI) can predict incidence of objective CRCI at 1 year follow-up with up to 100% accuracy (Kesler et al. 2017a). Given the discordance between objective and subjective cognitive measures, it is likely that different neural phenotypes underlie subjective and objective cognitive function, and therefore separate models are required to predict self-reported cognitive functioning. Being able to predict who will develop PRO-Cog is a vital next step to determine which patients should be targeted for early intervention and to improve personalized and precision medicine. Ideally, subtypes of CRCI would be established that distinguish patients who have objective or subjective impairment, or a combination of both. However, these definitions do not currently exist. Thus, the aim of this study was to determine if post-treatment PRO-Cog could also be predicted from baseline rsfMRI in patients with breast cancer.
Materials and Methods
ParticipantsAs part of an ongoing prospective longitudinal study of breast cancer and cognition we enrolled 76 newly diagnosed patients and 50 healthy female controls (Table 1). Patients included 42 who were scheduled for adjuvant chemotherapy and 34 who were not scheduled for chemotherapy. Patients were assessed prior to initiation of any treatment including neoadjuvant chemotherapy or surgery with general anesthesia 1 month following chemotherapy completion (or yoked interval) and 1 year later. Controls were assessed at yoked intervals. Participants were included in this study if they had completed both the baseline (Time 1) and 1-year assessments (Time 3). The Stanford University Institutional Review Board approved this study and all participants provided written informed consent (IRB #14623).
PRO-Cog AssessmentParticipants completed the Behavioral Rating Inventory of Executive Function (BRIEF), a 75-item self-report PROM questionnaire regarding everyday executive function behaviors (Roth et al. 2013) and the Prospective and Retrospective Memory Questionnaire (PRMQ), a 16-item self-report PROM questionnaire concerning memory failures (Crawford et al. 2003). Participants also completed the Clinical Assessment of Depression (CAD), a 50-item self-rating PROM questionnaire measuring depression, anxiety and cognitive fatigue (Aghakhani and Chan 2007). We focused on the Global Executive Composite score from the BRIEF, the Total Score from the PRMQ and the CAD. Test scores were converted to T scores, which have a mean of 50 and standard deviation of 10, based on the test’s published normative data.
Resting State fMRI Acquisition and PreprocessingRsfMRI data were acquired with a GE Discovery MR750 3.0 Tesla whole body scanner (GE Medical Systems) on the same day as the PRO-Cog questionnaires (see Supplemental Methods for further details). Data were preprocessed using Statistical Parametric Mapping 8 (Ashburner 2012) and CONN Toolbox (Whitfield-Gabrieli and Nieto-Castanon 2012) software. Full details are provided in the Supplementary Methods but briefly, preprocessing steps included realignment, segmentation of and co-registration with the anatomic volume, spatial normalization, smoothing, artifact detection and correction, wavelet despiking and band-pass filtering. Pairwise Pearson correlations were computed for the mean fMRI time courses of 268 brain regions (Shen et al. 2013) and normalized using Fisher r-to-z. This resulted in a 268 × 268 connectivity matrix, or connectome for each participant.
Statistical AnalysisWe first examined differences in the slopes of BRIEF, PRMQ, and CAD scores between patient groups (chemotherapy and chemotherapy naïve) and healthy controls using standard mixed effects linear modeling controlling for baseline scores. We used maximum likelihood estimation implemented in R Statistical Package (R Foundation, Vienna, Austria) with the “lme4” library (Bates et al. 2015). Data points missing due to participant attrition were handled assuming that data were missing at random. We also compared scores cross-sectionally between groups using t-tests.We then predicted 1-year follow-up BRIEF and PRMQ scores for patients with breast cancer from baseline rsfMRI using the connectome-based predictive modeling (CPM) protocol established by Shen et al. (2017) (Shen et al. 2017). Because the PRO-Cogs of breast cancer groups were significantly different from controls, especially at 1-year follow up, they were combined into a single group for CPM to increase the power of this primary analysis. For each tenfold cross-validation (CV) loop, feature selection/reduction was conducted on the training data (ninefolds) by correlating BRIEF (or PRMQ) score with every edge (connection) in the 268×268 connectome. Significantly correlated edges (p < 0.05) were summed for each of 8 previously defined functional networks (Shen et al. 2013) yielding a sparse set of 8 features that was then entered into a regression algorithm to predict BRIEF (or PRMQ) score. This model was then applied to the testing data (onefold) and the average, two-tailed, Pearson correlation between the predicted and actual scores was computed across folds. The p value for the correlation was calculated using two-tailed, Monte Carlo permutation testing. Specifically, a null distribution of correlation coefficients was computed for 5000 random permutations of the predicted scores and the p value was calculated as the proportion of times the permuted coefficients were greater than the original. We evaluated four different regression models: linear regression according the general linear model, support vector machine regression (SVR) (Cortes and Vapnik 1995) (C = 1) with a linear kernel, SVR with a radial basis function (RBF) kernel, and random forest (RF) regression (Breiman 2001) (trees = 500, mtry = 3).Cross-validation results in a different model fit within each fold and thus it is not possible to determine precisely the coefficients or significance values for the features. However, we explored group differences in the weights of the connectome edges that were selected at least 90% of the time across the CV folds, across all four models. Edge weights were compared by network membership between groups using analysis of variance (ANOVA). Tukey’s Honest Significant Difference (HSD) test for corrected pairwise comparisons was then conducted for significant (p<0.05) omnibus ANOVAs.Given the cost and complexity of imaging models, we also examined a non-imaging model for comparison. Specifically, we entered baseline neurocognitive testing scores into the same four regression models described above. The features for these models were scores from the following tests: Rey Auditory Verbal Learning Test (RAVLT) (de Sousa Magalhães et al. 2012) Immediate Recall, RAVLT Delayed Recall, Comprehensive Trail Making Test (CTMT) (Smith et al. 2008) Trails 1 through 5 and the Controlled Oral Word Association Test (Benton et al. 2000). Participants were also administered an experimental battery of computerized tests during this study but these have not yet been validated or normed and therefore were not included.All analyses were conducted in the R Statistical Package using the “randomForest” and “e1071” libraries for random forest and SVR, respectively.
Results
Linear mixed modeling showed that BRIEF scores increased over time in the chemotherapy group but were not significantly changed in the other two groups suggesting increased difficulties with everyday executive behaviors in those treated with chemotherapy (χ2 = 30.1, p < 0.0001). However, BRIEF score was significantly higher in patients with breast cancer compared to controls at 1-year follow-up (t=4.48, p< 0.001) and posthoc pairwise t tests controlled for false discovery rate confirmed that this effect was true for both chemotherapy treated (p = 0.0002, corrected) and chemotherapy naïve patients (p = 0.004, corrected).
PRMQ scores decreased over time in both patient groups compared to controls (χ2 = 24.8, p< 0.0001) indicating a decrease in memory function. PRMQ was significantly lower in patients with breast cancer compared to controls at 1-year follow-up (t = 5.13, p<0.001).
CAD scores also decreased in patients compared to controls (χ2 = 22.9, p< 0.0001) indicating a decrease in psychological distress over time (Fig. 1). However, CAD scores remained higher in patients compared to controls at 1-year follow-up (t = 2.58, p = 0.01).
As shown in Table 2, CPM results indicated that all 4 models successfully predicted both BRIEF and PRMQ scores (r>0.32, p< 0.005). SVR RBF showed the highest performance for BRIEF (r = 0.68, p = 0.0002, Fig. 2) and PRMQ (r = 0.44, p< 0.0004, Fig. 2). We repeated the SVR RBF models including baseline CAD score as a feature, but this did not result in marked improvement for BRIEF (r = 0.68, p = 0.0002) or PRMQ (r = 0.42, p = 0.0002).
Figure 3 illustrates the feature selected edge weights. PRMQ correlated edge weights differed significantly between groups in six out of eight networks (F> 11.0, p< 0.0001) with both patient groups showing significantly different weights compared to controls. The patient groups also differed from each other in medial frontal and visual 2 networks. BRIEF correlated edge weights differed significantly between the patient groups in the medial frontal (F = 11.0, p< 0.0001) and visual 2 networks (F = 63.4, p< 0.0001). The chemotherapy naïve group also differed significantly from controls in the visual 2 network.
There was no model of baseline neurocognitive test scores that could accurately predict BRIEF or PRMQ scores (r < 0.11, p > 0.36, Table 3).
Discussion
We examined longitudinal change in patient reported outcomes of cognitive function (PRO-Cog) and implemented connectome-based predictive modeling to forecast 1-year follow-up PRO-Cog from pre-treatment, baseline neuroimaging. Chemotherapy treated patients with breast cancer showed increased executive function difficulties over time compared to both chemotherapy naïve patients and healthy female controls. Both groups of patients showed increased memory difficulties compared to controls. Importantly, each patient group showed significantly lower perceived executive and memory functioning at 1-year follow up compared to controls making prediction of these outcomes clinically relevant for both groups. We determined four significant predictive models for self-reported executive function and memory using baseline connectome features. The best performing models accounted for 46% of the variance in executive function and 19% of the variance in memory function.
Support vector machine regression (SVR) with a radial basis function (RBF) kernel showed the best performance for predicting scores on both PRO-Cogs. In general, machine learning algorithms each have specific strengths and weaknesses and the RBF kernel tends to work well for non-linear problems. Whereas linear regression strives to find the best fit model that minimizes the error from a line, SVR attempts to minimize the error between an optimal margin from a hyperplane. The hyperplane allows SVR to fit more complex models than traditional regression. Specifically, the SVR kernel is the function used to map data that are not separable into a higher-dimensional space in which they become more easily separable (Cortes and Vapnik 1995). However, all of the connectome models performed quite similarly, and it is unlikely that they are significantly different from each other.
We previously showed that functional connectome is subtly altered in this patient cohort compared to controls prior to treatment initiation (Kesler et al. 2017b). Other groups have also demonstrated altered neurofunction in the interval between surgery and initiation of chemotherapy treatment (Scherling et al. 2011). The connectome represents key genetic, epigenetic and environmental factors including, for example, age, gender, education level and socioeconomic status (Ingalhalikar et al. 2014; Krishnadas et al. 2013; Sun et al. 2012; Zhang et al. 2018), as well as disease and treatment effects (Kesler et al. 2013a, 2017b; Sahnoune et al. 2018). Accordingly, we demonstrated that feature selected connectome edges differed significantly between patients and controls for six out of eight functional networks. These findings provide additional support suggesting baseline connectome differences may represent early changes from tumor pathogenesis and host-related factors that predispose patients to cognitive decline over time. These results also suggest that certain aspects of breast cancer and/or host factors have diffuse effects across the brain. Patient groups also differed significantly from each other in edge weights across both PRO-Cogs for the medial frontal and visual 2 networks suggesting that these two networks may be specifically vulnerable to factors that predispose patients towards receiving chemotherapy or not.
As noted above, psychological distress is strongly correlated with PRO-Cog. Most of the studies demonstrating this relationship have been cross-sectional. Our results indicate that CAD scores were indeed higher for patients than controls at all three time points but remained within the “normal” range. Based on T score interpretation, these scores reflected “average” distress level being right at the T score mean of 50. However, we excluded from enrollment in this study any participants who had significant histories of psychological conditions and/or treatments and therefore the present sample may underestimate distress in this population. We did show that CAD scores decreased significantly over time in patients suggesting that distress does not entirely explain the increase in PRO-Cog symptoms.
Our assessment of PRO-Cog symptoms was consistent with the prior literature in this field, and has the advantage of being domain specific (executive function and memory) but very limited in scope nonetheless. An innovative future direction for improving assessment of PRO-Cog involves the use of computerized adaptive PROMs, which utilize psychometric algorithms to iteratively select the most relevant questions for the patient, based on their level of cognitive ability. This process allows assessments to be shorter and more accurate than static, paper-based versions (Gibbons et al. 2016). Further sophistication in cognitive assessment may be brought about by the utilization of machine learning techniques to allow the quantification of natural language to identify cognitive functioning and deficits. Though a nascent field of research, these techniques could improve the ecological validity of cognitive assessments and increase the diversity of questions that can be included in these assessments (Gibbons et al. 2016; Hayati et al. 2019; Voleti et al. 2019).
Machine learning models using baseline neurocognitive features were not significant. These findings may be congruent with a larger body of research showing inconsistent correlation between subjective and objective measures of CRCI (Bray et al. 2018; Hutchinson et al. 2012). Neurocognitive tests may lack the specificity and/or ecological validity necessary for measuring cognitive processes (Horowitz et al. 2018) associated with subjective CRCI. It is also possible that different neurocognitive tests and/or a more comprehensive battery of such tests would yield improved prediction results. Higher dimensional neurocognitive data might be required such as item level responses from individual tests or ecological momentary assessment, which repeatedly measures behavior in naturalistic settings (Shiffman et al. 2008). However, our findings do support previous work suggesting that neuroimaging metrics may be superior to behavioral measures for predicting future cognitive outcomes (Gabrieli et al. 2015).
This study involved a small sample size and thus it requires replication in larger samples. Our findings are also potentially limited by our choice of connectome parcellation scheme, neuroimaging sequence, PRO-Cog measures, number of assessment time points, feature selection and modeling approaches. There are many options for each of these methods with no currently established standards. Larger or smaller parcellation schemes, alternate or multimodal neuroimaging (e.g. diffusion tensor imaging, task-based fMRI), a broader array of PRO-Cog questionnaires, additional time points and/or other regression algorithms/feature selection strategies may produce different results. We also did not tune any model parameters. We aimed to keep modeling simple for reproducibility and feasibility and also due to the small sample size but optimizing parameters may improve predictive accuracy.
In conclusion, baseline neuroimaging may be useful for predicting patient reported cognitive outcomes including executive function and memory complaints. This might assist in identifying patients in need of surveillance and/or early intervention for treatment-related cognitive effects. These data could also help inform pre-treatment clinical decision-making and education as well as patient planning in terms of certain life events such as return to work. Our findings provide additional support for the value of PROMs in CRCI research and their potential utility in clinical settings.
Supplementary Material
supplementary methods
