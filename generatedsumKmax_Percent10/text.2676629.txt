In contrast, both the spectral tilt and burst frequency of stop consonants, which are known to convey place of articulation information (e.g., Blumstein and Stevens, 1979), were significantly altered by noise. Two-way ANOVA (with repeated measures) indicated a significant effect of SNR level (F[1,12]=72.1, p<0.0005), a significant effect of stimulus processing (F[2,24]=538.1, p<0.0005) and a significant interaction (F[2,24]=7.9, p=0.002).Post-hoc tests (Scheffe) applied to the sentence scores at -5 dB SNR revealed highly significant differences (p<0.0005) between the scores obtained in the OFF and NSY (control) conditions, and between the NSY and CLN conditions. This can be attributed to the subjects making use of the vowel formant transitions into and out of the medial consonant. Figure 3 (bottom panel) shows an example spectrogram of a sentence processed using FC = 1000 Hz at -5 dB SNR.C. ProcedureThe procedure was identical to that used in Exp. Subjects were tested in a total of 16 (=4 values of FC × 2 SNR levels × 2 types of material) conditions. Two-way ANOVA (with repeated measures) applied to the sentence scores indicated a significant effect of SNR level (F[1,12]=1094.9, p<0.0005), a significant effect of frequency FC (F[5,60]=80.1, p<0.0005) and a significant interaction (F[5,60]=13.5, p<0.0005). Two-way ANOVA (with repeated measures) applied to the VCV scores indicated a significant effect of SNR level (F[1,12]=72.8, p<0.0005), a significant effect of frequency FC (F[5,60]=33.4, p<0.0005) and a significant interaction (F[5,60]=5.8, p<0.0005). Two-way ANOVA (with repeated measures) applied to the voicing scores indicated a significant effect of SNR level (F[1,12]=62.4, p<0.0005), a significant effect of frequency FC (F[5,60]=11.8, p<0.0005) and non-significant interaction (F[5,60]=1.1, p=0.36). Similar ANOVA applied to the manner and place feature scores revealed significant effects for SNR level and frequency FC and non-significant interactions.As shown in Figure 5 (top panel), large improvements were noted in the transmission of voicing information when FC ≥ 500 Hz. Significant (p<0.05) improvements to transmission of manner feature were noted for FC ≥ 3000 Hz at -5 dB SNR and for FC =12.5 kHz (CLN) at 0 dB SNR. The improvement in the transmission of manner of articulation information was found to be relatively smaller. Listeners detected words embedded in nonsense bisyllables more slowly when the bisyllables had two strong syllables than when the bisyllables had a strong and a weak syllable. The pre-lexical stage of this model consists of three steps. This step produces a set of articulator-based features (e.g., [high] tongue body, [anterior] tongue blade) which includes the place of articulation and voicing features. The male speaker was born in Texas and the female speaker was born in North Carolina. These SNR levels were chosen to avoid floor effects. The F0 detection algorithm was applied every 1-ms to the stimuli using a high-resolution fast Fourier transform (FFT), to provide for accurate temporal resolution of voiced/unvoiced boundaries. Segments with non-zero F0 values were initially classified as voiced and segments with zero F0 value (as determined by the STRAIGHT algorithm) were classified as unvoiced. Voiced stops produced with pre-voicing (e.g., /b/) as well as voiced fricatives (e.g. ConditionsThe thirteen subjects were quasirandomly assigned to the conditions involving processed IEEE sentences produced by the male and female speakers (seven listened to the IEEE sentences produced by a male speaker and six listened to the IEEE sentences produced by a female speaker). Stimuli were played to the listeners monaurally through Sennheiser HD 250 Linear II circumaural headphones at a comfortable listening level. In the consonant test, subjects were presented with a total of 12 repetitions of each consonant. All test sessions were preceded by one practice session in which the identity of the consonants was indicated to the listeners. To collect responses, a graphical interface was used that allowed the subjects to identify the consonants they heard by clicking on the corresponding button in the graphical interface. Two lists of sentences (i.e., 20 sentences) were used per condition, and none of the lists were repeated across conditions. 