In contrast, both the spectral tilt and burst frequency of stop consonants, which are known to convey place of articulation information (e.g., Blumstein and Stevens, 1979), were significantly altered by noise. Two-way ANOVA (with repeated measures) indicated a significant effect of SNR level (F[1,12]=72.1, p<0.0005), a significant effect of stimulus processing (F[2,24]=538.1, p<0.0005) and a significant interaction (F[2,24]=7.9, p=0.002).Post-hoc tests (Scheffe) applied to the sentence scores at -5 dB SNR revealed highly significant differences (p<0.0005) between the scores obtained in the OFF and NSY (control) conditions, and between the NSY and CLN conditions. This can be attributed to the subjects making use of the vowel formant transitions into and out of the medial consonant. The underlying mechanisms responsible for such large improvement are not clear from the present Experiment. Experiment 2: Contribution of Partial Spectral Information of Obstruent Consonants to Speech Intelligibility Figure 3 (bottom panel) shows an example spectrogram of a sentence processed using FC = 1000 Hz at -5 dB SNR.C. ProcedureThe procedure was identical to that used in Exp. Furthermore, evidence from animal neurophysiology studies (Smith, 1979; Delgutte and Kiang, 1984) suggests that the auditory system is particularly responsive (manifesting adaptation effects) to abrupt changes to the signal, such as those occurring at the onsets of landmarks. Subjects were tested in a total of 16 (=4 values of FC × 2 SNR levels × 2 types of material) conditions. Two-way ANOVA (with repeated measures) applied to the sentence scores indicated a significant effect of SNR level (F[1,12]=1094.9, p<0.0005), a significant effect of frequency FC (F[5,60]=80.1, p<0.0005) and a significant interaction (F[5,60]=13.5, p<0.0005). Two-way ANOVA (with repeated measures) applied to the VCV scores indicated a significant effect of SNR level (F[1,12]=72.8, p<0.0005), a significant effect of frequency FC (F[5,60]=33.4, p<0.0005) and a significant interaction (F[5,60]=5.8, p<0.0005). Two-way ANOVA (with repeated measures) applied to the voicing scores indicated a significant effect of SNR level (F[1,12]=62.4, p<0.0005), a significant effect of frequency FC (F[5,60]=11.8, p<0.0005) and non-significant interaction (F[5,60]=1.1, p=0.36). Similar ANOVA applied to the manner and place feature scores revealed significant effects for SNR level and frequency FC and non-significant interactions.As shown in Figure 5 (top panel), large improvements were noted in the transmission of voicing information when FC ≥ 500 Hz. Significant (p<0.05) improvements to transmission of manner feature were noted for FC ≥ 3000 Hz at -5 dB SNR and for FC =12.5 kHz (CLN) at 0 dB SNR. The improvement in the transmission of manner of articulation information was found to be relatively smaller. This measure assessed the contribution of low-frequency (<1 kHz) envelopes to speech intelligibility and was tested using a total of 120 sentences processed with FC ≤ 1000 Hz at -5 and 0 dB SNR levels. This measure assessed the contribution of low-frequency (<1 kHz) envelopes to speech intelligibility and was tested using a total of 120 sentences processed with FC ≤ 1000 Hz at -5 and 0 dB SNR levels. This measure assessed the contribution of low-frequency (<1 kHz) envelopes to speech intelligibility and was tested using a total of 120 sentences processed with FC ≤ 1000 Hz at -5 and 0 dB SNR levels. This measure assessed the contribution of low-frequency (<1 kHz) envelopes to speech intelligibility and was tested using a total of 120 sentences processed with FC ≤ 1000 Hz at -5 and 0 dB SNR levels. This measure assessed the contribution of low-frequency (<1 kHz) envelopes to speech intelligibility and was tested using a total of 120 sentences processed with FC ≤ 1000 Hz at -5 and 0 dB SNR levels. Listeners detected words embedded in nonsense bisyllables more slowly when the bisyllables had two strong syllables than when the bisyllables had a strong and a weak syllable. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Experiment 2 thus assesses the contribution of low- and high-frequency acoustic landmarks to speech recognition in noise. Cutler and Norris (1988) interpreted their data to suggest that strong syllables trigger the segmentation process. The pre-lexical stage of this model consists of three steps. This step produces a set of articulator-based features (e.g., [high] tongue body, [anterior] tongue blade) which includes the place of articulation and voicing features. The third step consolidates, taking context into account, all the cues collected in Step 2 to derive a sequence of features for each of the landmarks detected in Step 1. Restoring the acoustic landmarks helped improve performance significantly (see Figure 5). Second, the absence of reliable landmarks can disrupt the syllable structure, which is known to be important for determining word boundaries in fluent speech. Second, the absence of reliable landmarks can disrupt the syllable structure, which is known to be important for determining word boundaries in fluent speech. Therefore, not knowing when the syllable starts (i.e., the syllable onset) makes word boundary determination very difficult. The error analysis revealed that the word-initial phoneme errors were reduced by 32% when listeners had access to the low-frequency (FC ≤ 1000 Hz) acoustic landmarks. The error analysis revealed that the word-initial phoneme errors were reduced by 32% when listeners had access to the low-frequency (FC ≤ 1000 Hz) acoustic landmarks. At the very least, the high-frequency landmarks need to be made accessible to hearing-impaired listeners. At the very least, the high-frequency landmarks need to be made accessible to hearing-impaired listeners. The male speaker was born in Texas and the female speaker was born in North Carolina. The average long-term spectrum of the multi-talker babble is shown in Parikh and Loizou (2005). These SNR levels were chosen to avoid floor effects. The F0 detection algorithm was applied every 1-ms to the stimuli using a high-resolution fast Fourier transform (FFT), to provide for accurate temporal resolution of voiced/unvoiced boundaries. Segments with non-zero F0 values were initially classified as voiced and segments with zero F0 value (as determined by the STRAIGHT algorithm) were classified as unvoiced. Voiced stops produced with pre-voicing (e.g., /b/) as well as voiced fricatives (e.g. More precisely, the unvoiced portion of the following semivowel or vowel was absorbed in the stop release, and was thus classified as an obstruent consonant. More precisely, the unvoiced portion of the following semivowel or vowel was absorbed in the stop release, and was thus classified as an obstruent consonant. More precisely, the unvoiced portion of the following semivowel or vowel was absorbed in the stop release, and was thus classified as an obstruent consonant. The study by Mines et al  (1978) analyzed the distribution of phonemes taken from a large database (comprising nearly 104,000 phonemes) and found that the phonemes belonging in the obstruent class occur 34% of the time.C. The study by Mines et al  (1978) analyzed the distribution of phonemes taken from a large database (comprising nearly 104,000 phonemes) and found that the phonemes belonging in the obstruent class occur 34% of the time.C. ConditionsThe thirteen subjects were quasirandomly assigned to the conditions involving processed IEEE sentences produced by the male and female speakers (seven listened to the IEEE sentences produced by a male speaker and six listened to the IEEE sentences produced by a female speaker). Stimuli were played to the listeners monaurally through Sennheiser HD 250 Linear II circumaural headphones at a comfortable listening level. In the consonant test, subjects were presented with a total of 12 repetitions of each consonant. All test sessions were preceded by one practice session in which the identity of the consonants was indicated to the listeners. All test sessions were preceded by one practice session in which the identity of the consonants was indicated to the listeners. To collect responses, a graphical interface was used that allowed the subjects to identify the consonants they heard by clicking on the corresponding button in the graphical interface. Two lists of sentences (i.e., 20 sentences) were used per condition, and none of the lists were repeated across conditions. 